---
title: 多尺度+互促(特征拼接)+INR 去雨
date: 2025-03-27T10:54:27.000Z
tags: [可盐可甜]
category: 论文
comments: true
draft: false
---

---

## 双向多尺度隐式神经网络图像去雨

emmm这个系列就叫睡前读一会吧~

两天看一篇论文~~~

哇，好长的名字

首先这个是领域内的，所以就看一眼引入和method就好

### Abstact and Introduction

看了一眼摘要：传统是单尺度transformer，这篇文章有几个点，**端到端**，**多尺度**，transformer,探索潜在的特征(**隐式特征**)，然后把学习到的特征促进模型(**互促**)

一些词的解释，粗尺度：图像轮廓特征，细尺度：图像局部细节

从introduction来看，多尺度就是用多个不相等的transformer分支，学习尺度特征。

从粗学到细，有一步误差大后面就都毁了，所以需要一个**反馈网络，粗到细，细到粗**，尺度内有INR分支(学习常见的**雨退化特征**目前还没不知道这个是啥)，尺度间有双向分支

看完引入了，结构：多个transformer学习多个分支+分支内的INR学习退化特征+分支间用双向反馈机制

related work跳过了

**INR通过学习从坐标到信号值的映射来编码信号**对INR基本理解，似乎这个有点意思

仔细看了一下插图，采用全局架构，中间内容作为嵌入子图完成，配色感觉一般，但是结构真好，羡慕了

看完method部分了，后面就扔了

最开始做双线性下采样，得到S1，S2，S3不同尺度

INR提取无雨图像的特征，但是输入是有雨的，所以用局部多次采样然后取平均，用位置编码，最后用cell解码得到无雨特征

尺度间反馈机制也不难，从粗尺度流向细尺度，然后再从细尺度流向粗尺度中间无非就是unet和transformer不难

然后是损失函数Charbonnier损失、频率损失、边缘损失和L1范数等混合损失函数没啥技术含量

学习意义就是INR的思想和代码学一学，创新点在多尺度上，首先认识到多尺度用H和W进行约束即可，然后尺度间的交互的代码也要学，交互方法并没有用loss表示这些巧妙的idea而是直接拼接特征交互，基础薄弱，特征拼接也要学，好累

总体来说挺简单的，就这样吧

INR如果还没被吃干抹净的话，说不定能混口汤喝

读论文的技巧不多，不想分享就到吧

明天就把代码补上，再看一篇3D重建的
